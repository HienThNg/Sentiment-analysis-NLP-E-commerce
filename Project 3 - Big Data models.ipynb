{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46a68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
    "# !pip install -q findspark\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51a0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# %cd '/content/gdrive/MyDrive/DATA SCIENCE - ĐH KHTN/LDS9 - Big Data in Machine Learning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538f884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874e0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e574a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c03c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Project3-Sendo-Sentiment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa79e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.read.csv(\"Sendo_reviews_cleaned.csv\", inferSchema=True,header=True)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d1d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------------+------------------+------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------+--------+----------+---------+-----------+--------------------+\n",
      "|product_id|   customer_id|       full_name|      created_time|rating|             content|         content_raw|positive_words_count|negative_words_count|positive_emojis_count|negative_emojis_count|positive|negative|rating_new|sentiment|length_text|           temp_list|\n",
      "+----------+--------------+----------------+------------------+------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------+--------+----------+---------+-----------+--------------------+\n",
      "|  10119100|NguyenCatTuong|Nguyễn Cát Tường|20:22 | 21/12/2018|     4|    shop phục_vụ tốt|Shop phục vụ khá ...|                   1|                   0|                    0|                    0|       1|       0|         5| positive|          4|['shop', 'phục_vụ...|\n",
      "|  10119100|      VuPhuong|       Vũ Phương|15:00 | 10/12/2018|     3|      sản_phẩm mô_tả|Sản phẩm gần giốn...|                   1|                   0|                    0|                    0|       1|       0|         4| positive|          4|['sản_phẩm', 'mô_...|\n",
      "|  10119490|        lienla|         liên la|16:43 | 06/02/2021|     5|                hàng|Giao hàng nhanh b...|                   1|                   0|                    0|                    0|       1|       0|         6| positive|          1|            ['hàng']|\n",
      "|  10119490|      DoanHanh|       Đoàn Hạnh|22:06 | 19/07/2020|     4|    sản_phẩm dịch_vụ|Sản phẩm/dịch vụ ...|                   1|                   0|                    0|                    0|       1|       0|         5| positive|          4|['sản_phẩm', 'dịc...|\n",
      "|  10119490|   Phamthuhoai|   Phạm thu hoài|11:57 | 26/08/2019|     5|sản_phẩm dịch_vụ ...|Sản phẩm/dịch vụ ...|                   7|                   0|                    0|                    0|       7|       0|         6| positive|         25|['sản_phẩm', 'dịc...|\n",
      "+----------+--------------+----------------+------------------+------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------+--------+----------+---------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "229c5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- created_time: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_raw: string (nullable = true)\n",
      " |-- positive_words_count: string (nullable = true)\n",
      " |-- negative_words_count: integer (nullable = true)\n",
      " |-- positive_emojis_count: integer (nullable = true)\n",
      " |-- negative_emojis_count: integer (nullable = true)\n",
      " |-- positive: integer (nullable = true)\n",
      " |-- negative: integer (nullable = true)\n",
      " |-- rating_new: integer (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- length_text: string (nullable = true)\n",
      " |-- temp_list: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46635c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data['sentiment']!='6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa5d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  5267\n",
      "After:  5127\n"
     ]
    }
   ],
   "source": [
    "print('Before: ', data.count())\n",
    "\n",
    "cols = ['rating','content','sentiment']\n",
    "for col in cols:\n",
    "    data = data.filter(data[col].isNotNull())\n",
    "print('After: ', data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c1944f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| positive| 4619|\n",
      "|  neutral|  152|\n",
      "| negative|  356|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca7d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|             content|sentiment|\n",
      "+--------------------+---------+\n",
      "|    shop phục_vụ tốt| positive|\n",
      "|      sản_phẩm mô_tả| positive|\n",
      "|                hàng| positive|\n",
      "|    sản_phẩm dịch_vụ| positive|\n",
      "|sản_phẩm dịch_vụ ...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chọn những cột cần thiết\n",
    "data_new = data.select(['content', 'sentiment'])\n",
    "data_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb07677",
   "metadata": {},
   "source": [
    "#### Xử lý dữ liệu văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b4e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "860517f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------+\n",
      "|             content|sentiment|length|\n",
      "+--------------------+---------+------+\n",
      "|    shop phục_vụ tốt| positive|    16|\n",
      "|      sản_phẩm mô_tả| positive|    14|\n",
      "|                hàng| positive|     4|\n",
      "|    sản_phẩm dịch_vụ| positive|    16|\n",
      "|sản_phẩm dịch_vụ ...| positive|   103|\n",
      "|shop tư_vấn hướng...| positive|    28|\n",
      "|    sản_phẩm tốt đợi| positive|    16|\n",
      "|      sản_phẩm mô_tả|  neutral|    14|\n",
      "|sản_phẩm hàng đón...| positive|    40|\n",
      "|chuyên_nghiệp đón...| positive|    46|\n",
      "+--------------------+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_new = data_new.withColumn('length', length(data_new['content']))\n",
    "data_new.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1369b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights based on class distribution\n",
    "class_counts = data_new.groupBy(\"sentiment\").count()\n",
    "total_count = data_new.count()\n",
    "class_weights = class_counts.withColumn(\"weight\", total_count/ class_counts[\"count\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc892b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------------+\n",
      "|sentiment|count|            weight|\n",
      "+---------+-----+------------------+\n",
      "| positive| 4619| 1.109980515263044|\n",
      "|  neutral|  152| 33.73026315789474|\n",
      "| negative|  356|14.401685393258427|\n",
      "+---------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6d368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the calculated class weights with your original DataFrame\n",
    "data_new = data_new.join(class_weights, on=\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c02cddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+-----+-----------------+\n",
      "|sentiment|             content|length|count|           weight|\n",
      "+---------+--------------------+------+-----+-----------------+\n",
      "| positive|    shop phục_vụ tốt|    16| 4619|1.109980515263044|\n",
      "| positive|      sản_phẩm mô_tả|    14| 4619|1.109980515263044|\n",
      "| positive|                hàng|     4| 4619|1.109980515263044|\n",
      "| positive|    sản_phẩm dịch_vụ|    16| 4619|1.109980515263044|\n",
      "| positive|sản_phẩm dịch_vụ ...|   103| 4619|1.109980515263044|\n",
      "| positive|shop tư_vấn hướng...|    28| 4619|1.109980515263044|\n",
      "| positive|    sản_phẩm tốt đợi|    16| 4619|1.109980515263044|\n",
      "|  neutral|      sản_phẩm mô_tả|    14|  152|33.73026315789474|\n",
      "| positive|sản_phẩm hàng đón...|    40| 4619|1.109980515263044|\n",
      "| positive|chuyên_nghiệp đón...|    46| 4619|1.109980515263044|\n",
      "+---------+--------------------+------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_new.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbf0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='content', outputCol='token_text')\n",
    "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "class_to_num = StringIndexer(inputCol='sentiment', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "791f73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf', 'length','weight'], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ff6abe",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "408e5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9dd76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[class_to_num, tokenizer,\n",
    "                                  stopremove, count_vec,\n",
    "                                  idf, \n",
    "                                  clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17fe08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e4036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e13ed",
   "metadata": {},
   "source": [
    "### Training và Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64d288e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6c3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(1625,[0,7,23,162...|\n",
      "|  0.0|(1625,[1,2,1623,1...|\n",
      "|  0.0|(1625,[6,1623,162...|\n",
      "|  0.0|(1625,[1,3,1623,1...|\n",
      "|  0.0|(1625,[0,1,2,3,4,...|\n",
      "|  0.0|(1625,[7,13,14,15...|\n",
      "|  0.0|(1625,[0,1,29,162...|\n",
      "|  2.0|(1625,[1,2,1623,1...|\n",
      "|  0.0|(1625,[0,1,6,9,18...|\n",
      "|  0.0|(1625,[0,4,6,8,9,...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73addb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 4619|\n",
      "|  1.0|  356|\n",
      "|  2.0|  152|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.groupBy('label').count().show() # 0: positive, 1: negative, 2: neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e23dfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, testing) = clean_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542948ca",
   "metadata": {},
   "source": [
    "## Select model\n",
    "\n",
    "* Trong bài toán này, áp dụng các model sau đây, so sánh kết quả và chọn model tốt nhất\n",
    "    - NaiveBayes\n",
    "    - LogisticRegression\n",
    "    - DecisionTreeClassifier\n",
    "    - RandomForestClassifier\n",
    "    - GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d94e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b78dafb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 4619|\n",
      "|  1.0|  356|\n",
      "|  2.0|  152|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_counts = clean_data.groupBy(\"label\").count()\n",
    "class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d5183cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NaiveBayes\n",
    "t0= datetime.now()\n",
    "# Use defaults\n",
    "nb = NaiveBayes()\n",
    "nb_model = nb.fit(training)\n",
    "nb_predictions = nb_model.transform(testing)\n",
    "time_nb = datetime.now() -t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7b9ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LogisticRegression\n",
    "t0= datetime.now()\n",
    "logistic = LogisticRegression(featuresCol='features', labelCol= 'label', predictionCol='prediction')\n",
    "logistic_model = logistic.fit(training)\n",
    "logistic_predictions = logistic_model.transform(testing)\n",
    "time_logistic = datetime.now() -t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a794357",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DecisionTreeClassifier\n",
    "t0= datetime.now()\n",
    "# Create a classifier object and fit to the traning data\n",
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol= 'label', predictionCol='prediction')\n",
    "dtc_model = dtc.fit(training)\n",
    "dtc_predictions = dtc_model.transform(testing)\n",
    "time_dt = datetime.now() -t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e438fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier\n",
    "t0= datetime.now()\n",
    "rfc = RandomForestClassifier(featuresCol='features', labelCol= 'label', predictionCol='prediction')\n",
    "rfc_model = rfc.fit(training)\n",
    "rfc_predictions = rfc_model.transform(testing)\n",
    "time_rf = datetime.now() -t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e480ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## GBTClassifier\n",
    "# t0= datetime.now()\n",
    "# gbt = GBTClassifier(featuresCol='features', labelCol= 'label', predictionCol='prediction')\n",
    "# gbt_model = gbt.fit(training)\n",
    "# gbt_predictions = gbt_model.transform(testing)\n",
    "# time_gbt = datetime.now() -t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cb9a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "# select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='accuracy')\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='f1')\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='precisionByLabel')\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='recallByLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "863d020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "nb_acc = acc_evaluator.evaluate(nb_predictions)\n",
    "log_acc = acc_evaluator.evaluate(logistic_predictions)\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "# gbt_acc = acc_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "## f1\n",
    "nb_f1 = f1_evaluator.evaluate(nb_predictions)\n",
    "log_f1 = f1_evaluator.evaluate(logistic_predictions)\n",
    "dtc_f1 = f1_evaluator.evaluate(dtc_predictions)\n",
    "rfc_f1 = f1_evaluator.evaluate(rfc_predictions)\n",
    "# gbt_f1 = f1_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "## precision\n",
    "nb_precision = precision_evaluator.evaluate(nb_predictions)\n",
    "log_precision = precision_evaluator.evaluate(logistic_predictions)\n",
    "dtc_precision = precision_evaluator.evaluate(dtc_predictions)\n",
    "rfc_precision= precision_evaluator.evaluate(rfc_predictions)\n",
    "# gbt_precision = precision_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "## recall\n",
    "nb_recall = recall_evaluator.evaluate(nb_predictions)\n",
    "log_recall = recall_evaluator.evaluate(logistic_predictions)\n",
    "dtc_recall = recall_evaluator.evaluate(dtc_predictions)\n",
    "rfc_recall = recall_evaluator.evaluate(rfc_predictions)\n",
    "# gbt_recall = recall_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bbb94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Naive Bayes\n",
      "+ A single Naive Bayes has an accuracy of 90.79%\n",
      "+ A single Naive Bayes has an f1 score of 92.20%\n",
      "+ A single Naive Bayes has an precision score of 100.00%\n",
      "+ A single Naive Bayes has an recall score of 93.04%\n",
      "Total time Naive Bayes: 0:00:01.647500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.3.0-bin-hadoop3\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[869.  52.  13.]\n",
      " [  0.  45.  24.]\n",
      " [  0.   6.  22.]]\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   45|\n",
      "|  0.0|       1.0|   52|\n",
      "|  2.0|       2.0|   22|\n",
      "|  2.0|       1.0|    6|\n",
      "|  1.0|       2.0|   24|\n",
      "|  0.0|       0.0|  869|\n",
      "|  0.0|       2.0|   13|\n",
      "+-----+----------+-----+\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Logistic Regression\n",
      "+ A ansemble using Logistic has an accuracy of 96.51%\n",
      "+ A single Logistic has an f1 score of 96.77%\n",
      "+ A single Logistic has an precision score of 100.00%\n",
      "+ A single Logistic has an recall score of 98.29%\n",
      "Total time Logistic: 0:00:03.453211\n",
      "Confusion Matrix:\n",
      " [[918.  11.   5.]\n",
      " [  0.  53.  16.]\n",
      " [  0.   4.  24.]]\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   53|\n",
      "|  0.0|       1.0|   11|\n",
      "|  2.0|       2.0|   24|\n",
      "|  2.0|       1.0|    4|\n",
      "|  1.0|       2.0|   16|\n",
      "|  0.0|       0.0|  918|\n",
      "|  0.0|       2.0|    5|\n",
      "+-----+----------+-----+\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Decision Tree\n",
      "+ A single Decision Tree has an accuracy of 100.00%\n",
      "+ A single Decision Tree has an f1 score of 100.00%\n",
      "+ A single Decision Tree has an precision score of 100.00%\n",
      "+ A single Decision Tree has an recall score of 100.00%\n",
      "Total time Decision Tree: 0:00:02.483849\n",
      "Confusion Matrix:\n",
      " [[934.   0.   0.]\n",
      " [  0.  69.   0.]\n",
      " [  0.   0.  28.]]\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   69|\n",
      "|  2.0|       2.0|   28|\n",
      "|  0.0|       0.0|  934|\n",
      "+-----+----------+-----+\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Random Forest\n",
      "+ A Random Forest ensemble has an accuracy of 90.59%\n",
      "+ A Random Forest ensemble has an f1 score of 86.12%\n",
      "+ A Random Forest ensemble has an precision score of 90.59%\n",
      "+ A Random Forest ensemble has an recall score of 100.00%\n",
      "Total time Random Forest ensemble: 0:00:03.579087\n",
      "Confusion Matrix:\n",
      " [[934.   0.   0.]\n",
      " [ 69.   0.   0.]\n",
      " [ 28.   0.   0.]]\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0|   28|\n",
      "|  1.0|       0.0|   69|\n",
      "|  0.0|       0.0|  934|\n",
      "+-----+----------+-----+\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Results:\")\n",
    "print('-'*100)\n",
    "print('Naive Bayes')\n",
    "print(f'+ A single Naive Bayes has an accuracy of {nb_acc*100:.2f}%')\n",
    "print(f'+ A single Naive Bayes has an f1 score of {nb_f1*100:.2f}%')\n",
    "print(f'+ A single Naive Bayes has an precision score of {nb_precision*100:.2f}%')\n",
    "print(f'+ A single Naive Bayes has an recall score of {nb_recall*100:.2f}%')\n",
    "print('Total time Naive Bayes:', time_nb)\n",
    "print('Confusion Matrix: \\n',MulticlassMetrics(nb_predictions.select(['prediction','label']).rdd.map(tuple)).confusionMatrix().toArray())\n",
    "nb_predictions.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "print('-'*100)\n",
    "print('Logistic Regression')\n",
    "print(f'+ A ansemble using Logistic has an accuracy of {log_acc*100:.2f}%')\n",
    "print(f'+ A single Logistic has an f1 score of {log_f1*100:.2f}%')\n",
    "print(f'+ A single Logistic has an precision score of {log_precision*100:.2f}%')\n",
    "print(f'+ A single Logistic has an recall score of {log_recall*100:.2f}%')\n",
    "print('Total time Logistic:', time_logistic)\n",
    "print('Confusion Matrix:\\n',MulticlassMetrics(logistic_predictions.select(['prediction','label']).rdd.map(tuple)).confusionMatrix().toArray())\n",
    "logistic_predictions.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "print('-'*100)\n",
    "print('Decision Tree')\n",
    "print(f'+ A single Decision Tree has an accuracy of {dtc_acc*100:.2f}%')\n",
    "print(f'+ A single Decision Tree has an f1 score of {dtc_f1*100:.2f}%')\n",
    "print(f'+ A single Decision Tree has an precision score of {dtc_precision*100:.2f}%')\n",
    "print(f'+ A single Decision Tree has an recall score of {dtc_recall*100:.2f}%')\n",
    "print('Total time Decision Tree:', time_dt)\n",
    "print('Confusion Matrix:\\n',MulticlassMetrics(dtc_predictions.select(['prediction','label']).rdd.map(tuple)).confusionMatrix().toArray())\n",
    "dtc_predictions.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "print('-'*100)\n",
    "print('Random Forest')\n",
    "print(f'+ A Random Forest ensemble has an accuracy of {rfc_acc*100:.2f}%')\n",
    "print(f'+ A Random Forest ensemble has an f1 score of {rfc_f1*100:.2f}%')\n",
    "print(f'+ A Random Forest ensemble has an precision score of {rfc_precision*100:.2f}%')\n",
    "print(f'+ A Random Forest ensemble has an recall score of {rfc_recall*100:.2f}%')\n",
    "print('Total time Random Forest ensemble:', time_rf)\n",
    "print('Confusion Matrix:\\n',MulticlassMetrics(rfc_predictions.select(['prediction','label']).rdd.map(tuple)).confusionMatrix().toArray())\n",
    "rfc_predictions.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# print('-'*100)\n",
    "# print(f'+ A ansemble using GBT has an accuracy of\\t\\t{gbt_acc*100:.2f}%')\n",
    "# print(f'+ A single Naive Bayes has an f1 score of\\t\\t\\t{gbt_f1*100:.2f}%')\n",
    "# print(f'+ A single Naive Bayes has an precision score of\\t\\t\\t{gbt_precision*100:.2f}%')\n",
    "# print(f'+ A single Naive Bayes has an recall score of\\t\\t\\t{gbt_recall*100:.2f}%')\n",
    "# print('Confusion Matrix:'MulticlassMetrics(gbt_predictions.select(['prediction','label']).rdd.map(tuple)).confusionMatrix().toArray())\n",
    "# gbt_predictions.groupBy('label', 'prediction').count().show()\n",
    "print('-'*42*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737a968",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "* Từ kết quả trên có thể thấy thời gian chạy giữa các mô hình không có quá nhiều chênh lệch\n",
    "* Decision Tree tuy có các chỉ số rất cao, tuy nhiên vì tất cả đều là 100% nên có sẽ xảy ra hiện tượng bias khi dự đoán dữ liệu mới\n",
    "*Thời gian chạy giữa các mô hình không chênh lệch quá nhiều\n",
    "* Vì vậy, chọn mô hình có chỉ số cao thứ 2 là Logistic Regression cho dữ liệu này"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b74f63",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a26611a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72fc9d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260346879943813"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(training)\n",
    "\n",
    "predictions = cvModel.transform(testing)\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae164179",
   "metadata": {},
   "source": [
    "* Kết quả không cải thiện so với default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470b417",
   "metadata": {},
   "source": [
    "## Áp dụng model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa676a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(featuresCol='features', labelCol= 'label', predictionCol='prediction')\n",
    "logistic_model = logistic.fit(training)\n",
    "logistic_predictions = logistic_model.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea91ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "log_acc = acc_evaluator.evaluate(logistic_predictions)\n",
    "\n",
    "## f1\n",
    "log_f1 = f1_evaluator.evaluate(logistic_predictions)\n",
    "\n",
    "## precision\n",
    "log_precision = precision_evaluator.evaluate(logistic_predictions)\n",
    "\n",
    "## recall\n",
    "log_recall = recall_evaluator.evaluate(logistic_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "668cf907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "+ A ansemble using Logistic has an accuracy of 96.51%\n",
      "+ A single Logistic has an f1 score of 96.77%\n",
      "+ A single Logistic has an precision score of 100.00%\n",
      "+ A single Logistic has an recall score of 98.29%\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   53|\n",
      "|  0.0|       1.0|   11|\n",
      "|  2.0|       2.0|   24|\n",
      "|  2.0|       1.0|    4|\n",
      "|  1.0|       2.0|   16|\n",
      "|  0.0|       0.0|  918|\n",
      "|  0.0|       2.0|    5|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(f'+ A ansemble using Logistic has an accuracy of {log_acc*100:.2f}%')\n",
    "print(f'+ A single Logistic has an f1 score of {log_f1*100:.2f}%')\n",
    "print(f'+ A single Logistic has an precision score of {log_precision*100:.2f}%')\n",
    "print(f'+ A single Logistic has an recall score of {log_recall*100:.2f}%')\n",
    "logistic_predictions.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c612e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
